{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from tone_functions import categories, get_tone_data\n",
    "from numerical_intensity import num_count\n",
    "from fl_sents import prop_fl_sents\n",
    "\n",
    "conn_string = 'postgresql://' + os.environ['PGHOST'] + '/' + os.environ['PGDATABASE']\n",
    "engine = create_engine(conn_string)\n",
    "\n",
    "input_schema = \"streetevents\"\n",
    "input_table = \"speaker_data\"\n",
    "output_schema = \"streetevents\"\n",
    "output_table = \"linguistic_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileNames(output_table, output_schema, num_files=None):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Using LIMIT is much faster than getting all files and ditching\n",
    "    # unneeded ones.\n",
    "    if num_files==None:\n",
    "        limit_clause = \"\"\n",
    "    else:\n",
    "        limit_clause = \"LIMIT %s\" % (num_files)\n",
    "\n",
    "    # Get a list of unprocessed files. Query differs according to whether\n",
    "    # any files have been processed (i.e., output_table exists)\n",
    "    conn = engine.connect()\n",
    "    table_exists = engine.dialect.has_table(conn, output_table, schema=output_schema)\n",
    "    conn.close()\n",
    "\n",
    "    if table_exists:\n",
    "        sql = \"\"\"\n",
    "            WITH latest_call AS (\n",
    "                SELECT file_name, last_update\n",
    "                FROM streetevents.calls\n",
    "                WHERE event_type=1)\n",
    "            SELECT DISTINCT file_name, last_update\n",
    "            FROM latest_call\n",
    "            EXCEPT\n",
    "            SELECT file_name, last_update\n",
    "            FROM %s.%s\n",
    "            %s\n",
    "        \"\"\" % (output_schema, output_table, limit_clause)\n",
    "        files = pd.read_sql(sql, engine)\n",
    "    else:\n",
    "        sql = \"\"\"CREATE TABLE %s.%s\n",
    "                (\n",
    "                    file_name text,\n",
    "                    last_update timestamp with time zone,\n",
    "                    speaker_name text,\n",
    "                    employer text,\n",
    "                    role text,\n",
    "                    speaker_number integer,\n",
    "                    context text,\n",
    "                    language text,\n",
    "                    positive int,\n",
    "                    negative int,\n",
    "                    uncertainty int,\n",
    "                    litigious int,\n",
    "                    modal_strong int,\n",
    "                    modal_weak int,\n",
    "                    num_count int)\n",
    "            \"\"\" % (output_schema, output_table)\n",
    "        engine.execute(sql)\n",
    "\n",
    "        sql = \"\"\"\n",
    "            SELECT DISTINCT file_name, last_update\n",
    "            FROM streetevents.calls\n",
    "            WHERE event_type=1\n",
    "            %s\n",
    "        \"\"\" % (limit_clause)\n",
    "        files = pd.read_sql(sql, engine)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFile(file_name):\n",
    "\n",
    "    # Get syllable data for the file_name\n",
    "    speaker_data = getLFData(file_name)\n",
    "    for cat in categories:\n",
    "        speaker_data[cat] = speaker_data['speaker_text'].map(lambda x: get_tone_data(x, cat))    \n",
    "    speaker_data['num_count'] = speaker_data['speaker_text'].map(num_count)\n",
    "    speaker_data['last_update'] = speaker_data['last_update'].map(lambda x: str(x))\n",
    "    speaker_data = speaker_data.drop(['speaker_text'], 1)\n",
    "\n",
    "    # Submit dataframe to database\n",
    "    conn = engine.connect()\n",
    "    speaker_data.to_sql(output_table, conn, schema=output_schema, if_exists='append',\n",
    "              index=False)\n",
    "    conn.close()\n",
    "\n",
    "def getLFData(file_name):\n",
    "    from pandas.io.sql import read_sql\n",
    "    \n",
    "    conn = engine.connect()\n",
    "    table_exists = engine.dialect.has_table(conn, output_table, schema=output_schema)\n",
    "    conn.close()\n",
    "\n",
    "    # It may be better to explicitly create the table elsewhere.\n",
    "    # Checking like this might be slower.\n",
    "    if table_exists:\n",
    "        sql = \"DELETE FROM %s.%s WHERE file_name='%s'\" % \\\n",
    "            (output_schema, output_table, file_name)\n",
    "\n",
    "        engine.execute(sql)\n",
    "\n",
    "\n",
    "    sql = \"\"\"\n",
    "        SELECT file_name, last_update, speaker_name, employer, role, \n",
    "            speaker_number, context, speaker_text\n",
    "        FROM %s.%s\n",
    "        WHERE file_name='%s'\n",
    "        \"\"\" % (input_schema, input_table, file_name)\n",
    "\n",
    "    df = read_sql(sql, engine)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "diff = np.empty(10)\n",
    "for i in np.arange(10):\n",
    "    start = time.time()\n",
    "    files = getFileNames(output_table, output_schema, 10000*(i+1))\n",
    "    end = time.time()\n",
    "    diff[i] = end - start\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(10000*(np.arange(10) + 1), diff)\n",
    "plt.ylabel('import time (sec)')\n",
    "plt.xlabel('number of files')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = getFileNames(output_table, output_schema, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeProcessFile(file):\n",
    "    start = time.time()\n",
    "    processFile(file)\n",
    "    end = time.time()\n",
    "    return end - start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_process = [timeProcessFile(file) for file in files['file_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(time_process)\n",
    "plt.xlabel('Seconds')\n",
    "plt.ylabel('Number of observations')\n",
    "plt.title('Histogram of process_file')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
